title: “Data Mining - H3” author: “Wenhan Li, Bruce Hu, Eric Xia” date:
“03/27/2023” output: md\_document

## Problem 1-What causes what?

1.  Running a simple regression of “Crime” on “Police” to understand how
    more cops in the streets affect crime may suffer from several
    issues, such as omitted variable bias, spurious correlation, and
    endogeneity. For example, for omitted variable bias, there are
    likely other factors that can affect crime rates (such as poverty,
    unemployment, and education). Not including these variables in the
    analysis, then their effects on crime will be confounded with the
    effect of police. For spurious correlation, it is possible that the
    relationship between police and crime is bilateral, meaning higher
    crime rates may lead to increased police presence rather than the
    other way around. This means that running the regression of “Crime”
    on “Police” would produce a spurious result, suggesting that more
    police cause more crime. Lastly, the number of police officers in a
    city is likely to be endogenous. For example, a city with high crime
    rates may be more likely to hire additional police officers, which
    leads to a positive correlation between police and crime rates.

2.  The researchers from UPenn exploited the fact that police deployment
    decisions in Philadelphia were largely based on budget constraints
    and operational demands, which created natural variation in the
    number of police officers patrolling different areas of the city. To
    estimate the causal effect of police on crime rates, the researchers
    used a regression discontinuity design (RDD) that leveraged the fact
    that police deployment decisions were made based on a predetermined
    threshold of Part 1 crimes reported in each police district. This
    threshold was used to allocate resources, and as a result, police
    districts that had slightly higher crime rates than the threshold
    received more resources and hence more police presence than
    districts with slightly lower crime rates. This created a natural
    experiment that allowed the researchers to estimate the causal
    effect of police presence on crime rates by comparing the crime
    rates in the districts just above and below the threshold. The
    researchers estimated the effect of police presence on crime rates
    using linear regression models and controlling for a variety of
    confounding factors, such as socio-economic characteristics, weather
    conditions, and time trends. The results of their analysis,
    presented in Table 2 of their paper, showed that the presence of
    police had a significant and negative effect on crime rates,
    particularly for violent crimes. Specifically, they found that an
    increase in police presence by one standard deviation (equivalent to
    about 9 officers per square mile) reduced the rate of violent crimes
    by about 4% and the rate of property crimes by about 3%. These
    effects were robust to a variety of sensitivity analyses and
    alternative specifications of the model.

3.  They had to control for Metro ridership because it is possible that
    changes in crime patterns were related to changes metro ridership.
    It is possible that crimes that would have otherwise occurred in
    metro stations and trains were instead being prevented or deterred
    by the increased police presence. Controlling for metro ridership
    allows the researchers to separate the effect of police deployment
    from other factors that may have influenced crime rates in and
    around metro stations.

4.  The first column shows that the dependent variable is the natural
    log of subway crime, and the key independent variable of interest is
    a dummy variable indicating whether there was a police officer
    present at the metro station. The model also includes a set of
    control variables, such as time of day, day of week, station
    characteristics, and neighborhood demographics. The results suggest
    that the presence of a police officer at a subway station is
    associated with a statistically significant reduction in subway
    crime. The coefficient on the police presence variable is negative
    and statistically significant at the 1% level, indicating that the
    probability of a subway crime occurrence is lower when a police
    officer is present at the station. The magnitude of the coefficient
    suggests that the presence of one police officer reduces the
    probability of a subway crime occurrence by about 50%. In
    conclusion, the model suggests that the presence of police officers
    at subway stations has a significant deterrent effect on subway
    crime.

### Tree modeling: dengue cases

We chose to use normal dengue cases (not log) to identify the nominal
change in total cases instead of a percentage change.

#### CART Models.

![unnamed-chunk-2-1](https://user-images.githubusercontent.com/122301851/228050874-97702086-c3b0-44e8-b9a9-e2351c04117e.png)
![unnamed-chunk-2-2](https://user-images.githubusercontent.com/122301851/228050918-42f21a20-8c8e-46dd-98c3-40f96c4a2246.png)
![unnamed-chunk-2-3](https://user-images.githubusercontent.com/122301851/228050959-33614c0e-4a02-4465-899e-399f87950ea8.png)
![unnamed-chunk-2-4](https://user-images.githubusercontent.com/122301851/228050984-c8dcd55f-11ca-4c1e-8b05-b9994f8e7517.png)

#### Random Forest.

![unnamed-chunk-3-1](https://user-images.githubusercontent.com/122301851/228051007-b3bf4311-1287-40e2-971c-8f25a0cac218.png)

#### Gradient-Boosted Trees.

    ## Distribution not specified, assuming gaussian ...

![unnamed-chunk-4-1](https://user-images.githubusercontent.com/122301851/228051022-7e93cf20-1b18-4260-894c-a7a36623fc94.png)

    ## [1] 32
    ## attr(,"smoother")
    ## Call:
    ## loess(formula = object$oobag.improve ~ x, enp.target = min(max(4, 
    ##     length(x)/10), 50))
    ## 
    ## Number of Observations: 500 
    ## Equivalent Number of Parameters: 39.85 
    ## Residual Standard Error: 1.883

#### Compare RMSE between models.

    ## [1] 41.08469

    ## [1] 40.23717

    ## [1] 44.28972

Above RMSE’s correspond to pruned tree, rf, and gbm, respectively. We
find that RMSE of rf is smallest.

#### Partial dependence plots.

![unnamed-chunk-6-1](https://user-images.githubusercontent.com/122301851/228051043-b640a68c-1c58-4760-afd4-91e2c8dbcab5.png)
![unnamed-chunk-6-2](https://user-images.githubusercontent.com/122301851/228051071-dee7db2f-88b2-4f09-ba2b-15c8c4a7d02c.png)
![unnamed-chunk-6-3](https://user-images.githubusercontent.com/122301851/228051080-32b1bf49-361f-4886-81fb-1ba006714d2a.png)

## Predictive model building: green certification.

#### Introduction

We attempt to build the best predictive model possible for revenue per
square foot per calendar year, and to use this model to quantify the
average change in rental income per square foot with green
certification, holding other features of the building constant. We chose
to collapse LEED and EnergyStar into a single “green certified”
category. Through this study, we attempt to identify the relationship
between green certification and rental revenue. The implication is that
we hope this can become an incentive for rental property owners to
obtain green certifications.

#### Data

The data we have contains 7,894 commercial rental properties from across
the United States. Of which, 685 properties have been awarded either
LEED or EnergyStar certification as a green building. The data also
contains other variables that identify various properties of the
properties, such as property ID, rent, size, and annual precipitation in
inches in the building’s geographical location. We clean the data by
removing non-existing data and creating the variable “revenue” that we
will use as our endogeneous variable.

Then we split the data into testing group and training group. This
concludes data preparation.

#### Model

We start by constructing four models to estimate this relationship and
then find the best model out of the four. These four models are a
stepwise regression model and three tree models covered in lecture.
These three models are classification and regression trees, rf, and
bagging. We use the variables size + empl\_gr + stories + age +
renovated + class\_a + class\_b + green\_rating + amenities +
total\_dd\_07 + Precipitation + Gas\_Costs + Electricity\_Costs +
City\_Market\_Rent. We chose these variables because we believe that
they are neither irrelevant to the regression (such as the property ID)
nor serially correlated with the dependent variables (such as rent with
revenue). We also eliminated the variables that seem most likely to have
linear relationships with other exogenous variables.

#### Model 1: stepwise selection.

    ## lm(formula = revenue ~ size + class_a + class_b + green_rating + 
    ##     amenities + total_dd_07 + Gas_Costs + Electricity_Costs + 
    ##     City_Market_Rent, data = gb_train)

    ##       (Intercept)              size           class_a           class_b 
    ##     -1.382555e+01      7.622718e-06      4.609057e+00      2.862180e+00 
    ##      green_rating         amenities       total_dd_07         Gas_Costs 
    ##      1.474418e+00      1.613448e+00      5.872254e-04     -2.656018e+02 
    ## Electricity_Costs  City_Market_Rent 
    ##      1.409468e+02      1.016761e+00

    ## [1] 8.767476

    ## 
    ## Call:
    ## lm(formula = revenue ~ size + class_a + class_b + green_rating + 
    ##     amenities + total_dd_07 + Gas_Costs + Electricity_Costs + 
    ##     City_Market_Rent, data = gb_train)
    ## 
    ## Residuals:
    ##     Min      1Q  Median      3Q     Max 
    ## -63.288  -4.379  -0.002   3.852 176.328 
    ## 
    ## Coefficients:
    ##                     Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept)       -1.383e+01  1.128e+00 -12.259  < 2e-16 ***
    ## size               7.623e-06  5.509e-07  13.836  < 2e-16 ***
    ## class_a            4.609e+00  4.913e-01   9.382  < 2e-16 ***
    ## class_b            2.862e+00  4.221e-01   6.781 1.30e-11 ***
    ## green_rating       1.474e+00  5.030e-01   2.931  0.00339 ** 
    ## amenities          1.613e+00  3.159e-01   5.108 3.36e-07 ***
    ## total_dd_07        5.872e-04  1.088e-04   5.395 7.10e-08 ***
    ## Gas_Costs         -2.656e+02  6.750e+01  -3.935 8.42e-05 ***
    ## Electricity_Costs  1.409e+02  2.760e+01   5.106 3.39e-07 ***
    ## City_Market_Rent   1.017e+00  1.519e-02  66.946  < 2e-16 ***
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 10.82 on 6246 degrees of freedom
    ## Multiple R-squared:  0.542,  Adjusted R-squared:  0.5413 
    ## F-statistic: 821.2 on 9 and 6246 DF,  p-value: < 2.2e-16

![unnamed-chunk-9-1](https://user-images.githubusercontent.com/122301851/228051117-a6c779aa-dd54-4a36-96b7-e792438d0817.png)
![unnamed-chunk-9-2](https://user-images.githubusercontent.com/122301851/228051138-0164f2dc-57a1-4e86-bd46-c72e9d1a25d0.png)
![unnamed-chunk-9-3](https://user-images.githubusercontent.com/122301851/228051160-2e1910da-1d38-4c18-8707-5b5d47334664.png)
![unnamed-chunk-9-4](https://user-images.githubusercontent.com/122301851/228051176-4ba65ae2-8154-40a1-9b24-41e55b5fbb62.png)

#### Model 2: Classification and Regression Trees.

    ## Call:
    ## rpart(formula = revenue ~ size + empl_gr + stories + age + renovated + 
    ##     class_a + class_b + green_rating + amenities + total_dd_07 + 
    ##     Precipitation + Gas_Costs + Electricity_Costs + City_Market_Rent, 
    ##     data = gb_train)
    ##   n= 6256 
    ## 
    ##           CP nsplit rel error    xerror       xstd
    ## 1 0.29991267      0 1.0000000 1.0004491 0.06786316
    ## 2 0.11417184      1 0.7000873 0.7028810 0.05706745
    ## 3 0.04209233      2 0.5859155 0.5964356 0.04493811
    ## 4 0.03675824      3 0.5438232 0.5807008 0.04502022
    ## 5 0.02254044      4 0.5070649 0.5352304 0.04034576
    ## 6 0.01616320      5 0.4845245 0.5051272 0.03518224
    ## 7 0.01042387      6 0.4683613 0.5025549 0.03529764
    ## 8 0.01000000      7 0.4579374 0.4905306 0.03507197
    ## 
    ## Variable importance
    ##  City_Market_Rent Electricity_Costs     Precipitation       total_dd_07 
    ##                43                14                10                 9 
    ##              size         Gas_Costs           empl_gr         amenities 
    ##                 7                 6                 5                 2 
    ##           stories           class_a               age 
    ##                 2                 1                 1 
    ## 
    ## Node number 1: 6256 observations,    complexity param=0.2999127
    ##   mean=24.22804, MSE=255.1183 
    ##   left son=2 (4311 obs) right son=3 (1945 obs)
    ##   Primary splits:
    ##       City_Market_Rent  < 32.1625    to the left,  improve=0.29991270, (0 missing)
    ##       Electricity_Costs < 0.0318248  to the left,  improve=0.17379220, (0 missing)
    ##       total_dd_07       < 6279.5     to the right, improve=0.09403110, (0 missing)
    ##       empl_gr           < 1.17       to the right, improve=0.08023222, (0 missing)
    ##       Gas_Costs         < 0.01027147 to the left,  improve=0.07469320, (0 missing)
    ##   Surrogate splits:
    ##       Electricity_Costs < 0.0318248  to the left,  agree=0.769, adj=0.258, (0 split)
    ##       Gas_Costs         < 0.01429911 to the left,  agree=0.733, adj=0.142, (0 split)
    ##       empl_gr           < 1.17       to the right, agree=0.733, adj=0.140, (0 split)
    ##       Precipitation     < 45.64      to the left,  agree=0.722, adj=0.106, (0 split)
    ##       total_dd_07       < 3056.5     to the right, agree=0.722, adj=0.104, (0 split)
    ## 
    ## Node number 2: 4311 observations,    complexity param=0.03675824
    ##   mean=18.35262, MSE=73.76246 
    ##   left son=4 (1591 obs) right son=5 (2720 obs)
    ##   Primary splits:
    ##       City_Market_Rent < 20.2875    to the left,  improve=0.18449290, (0 missing)
    ##       class_a          < 0.5        to the left,  improve=0.08536825, (0 missing)
    ##       age              < 44.5       to the right, improve=0.06479389, (0 missing)
    ##       total_dd_07      < 2191.5     to the right, improve=0.06235336, (0 missing)
    ##       Gas_Costs        < 0.01027147 to the left,  improve=0.05096383, (0 missing)
    ##   Surrogate splits:
    ##       Gas_Costs         < 0.01027147 to the left,  agree=0.742, adj=0.301, (0 split)
    ##       empl_gr           < 3.33       to the right, agree=0.729, adj=0.265, (0 split)
    ##       total_dd_07       < 7178.5     to the right, agree=0.701, adj=0.191, (0 split)
    ##       Precipitation     < 47.815     to the right, agree=0.668, adj=0.101, (0 split)
    ##       Electricity_Costs < 0.02169062 to the left,  agree=0.649, adj=0.048, (0 split)
    ## 
    ## Node number 3: 1945 observations,    complexity param=0.1141718
    ##   mean=37.25063, MSE=410.9838 
    ##   left son=6 (1736 obs) right son=7 (209 obs)
    ##   Primary splits:
    ##       City_Market_Rent  < 51.9       to the left,  improve=0.2279571, (0 missing)
    ##       Electricity_Costs < 0.04163247 to the left,  improve=0.1966220, (0 missing)
    ##       Precipitation     < 47.43      to the left,  improve=0.1966220, (0 missing)
    ##       total_dd_07       < 5906       to the left,  improve=0.1708813, (0 missing)
    ##       size              < 712000     to the left,  improve=0.1580011, (0 missing)
    ##   Surrogate splits:
    ##       Precipitation     < 47.43      to the left,  agree=0.951, adj=0.545, (0 split)
    ##       Electricity_Costs < 0.04163247 to the left,  agree=0.951, adj=0.545, (0 split)
    ##       total_dd_07       < 5906       to the left,  agree=0.942, adj=0.459, (0 split)
    ##       size              < 712000     to the left,  agree=0.897, adj=0.043, (0 split)
    ##       stories           < 54.5       to the left,  agree=0.896, adj=0.029, (0 split)
    ## 
    ## Node number 4: 1591 observations
    ##   mean=13.52918, MSE=40.18658 
    ## 
    ## Node number 5: 2720 observations
    ##   mean=21.17397, MSE=71.83317 
    ## 
    ## Node number 6: 1736 observations,    complexity param=0.02254044
    ##   mean=33.89219, MSE=211.2169 
    ##   left son=12 (921 obs) right son=13 (815 obs)
    ##   Primary splits:
    ##       amenities        < 0.5        to the left,  improve=0.09811207, (0 missing)
    ##       size             < 733569     to the left,  improve=0.09473780, (0 missing)
    ##       City_Market_Rent < 41.01      to the left,  improve=0.09214692, (0 missing)
    ##       class_a          < 0.5        to the left,  improve=0.08811013, (0 missing)
    ##       stories          < 7.5        to the left,  improve=0.08513628, (0 missing)
    ##   Surrogate splits:
    ##       class_a   < 0.5        to the left,  agree=0.751, adj=0.469, (0 split)
    ##       size      < 134648.5   to the left,  agree=0.735, adj=0.436, (0 split)
    ##       age       < 48.5       to the right, agree=0.728, adj=0.420, (0 split)
    ##       stories   < 8.5        to the left,  agree=0.683, adj=0.325, (0 split)
    ##       Gas_Costs < 0.01029808 to the left,  agree=0.637, adj=0.227, (0 split)
    ## 
    ## Node number 7: 209 observations,    complexity param=0.04209233
    ##   mean=65.14654, MSE=1198.423 
    ##   left son=14 (201 obs) right son=15 (8 obs)
    ##   Primary splits:
    ##       size      < 1239546    to the left,  improve=0.26821610, (0 missing)
    ##       stories   < 44.5       to the left,  improve=0.11905900, (0 missing)
    ##       age       < 38.5       to the right, improve=0.04371162, (0 missing)
    ##       amenities < 0.5        to the left,  improve=0.02534084, (0 missing)
    ##       class_a   < 0.5        to the left,  improve=0.02343489, (0 missing)
    ## 
    ## Node number 12: 921 observations
    ##   mean=29.60992, MSE=192.7208 
    ## 
    ## Node number 13: 815 observations,    complexity param=0.0161632
    ##   mean=38.73142, MSE=187.9774 
    ##   left son=26 (784 obs) right son=27 (31 obs)
    ##   Primary splits:
    ##       size              < 716902.5   to the left,  improve=0.16838460, (0 missing)
    ##       stories           < 50.5       to the left,  improve=0.16791630, (0 missing)
    ##       City_Market_Rent  < 41.42      to the left,  improve=0.09521836, (0 missing)
    ##       Electricity_Costs < 0.0318248  to the left,  improve=0.05688876, (0 missing)
    ##       class_a           < 0.5        to the left,  improve=0.02903261, (0 missing)
    ##   Surrogate splits:
    ##       stories < 38.5       to the left,  agree=0.984, adj=0.581, (0 split)
    ##       age     < 0.5        to the right, agree=0.963, adj=0.032, (0 split)
    ## 
    ## Node number 14: 201 observations
    ##   mean=61.56974, MSE=784.6433 
    ## 
    ## Node number 15: 8 observations
    ##   mean=155.0136, MSE=3197.117 
    ## 
    ## Node number 26: 784 observations,    complexity param=0.01042387
    ##   mean=37.61269, MSE=138.9886 
    ##   left son=52 (447 obs) right son=53 (337 obs)
    ##   Primary splits:
    ##       City_Market_Rent  < 38.5325    to the left,  improve=0.15267650, (0 missing)
    ##       size              < 96882.5    to the left,  improve=0.07165840, (0 missing)
    ##       Electricity_Costs < 0.0318248  to the left,  improve=0.06247817, (0 missing)
    ##       Gas_Costs         < 0.01410661 to the left,  improve=0.05753793, (0 missing)
    ##       stories           < 9.5        to the left,  improve=0.03620812, (0 missing)
    ##   Surrogate splits:
    ##       Gas_Costs         < 0.01410661 to the left,  agree=0.855, adj=0.662, (0 split)
    ##       empl_gr           < 1.46       to the right, agree=0.782, adj=0.493, (0 split)
    ##       Precipitation     < 45.64      to the left,  agree=0.782, adj=0.493, (0 split)
    ##       total_dd_07       < 5381.5     to the left,  agree=0.769, adj=0.463, (0 split)
    ##       Electricity_Costs < 0.0352687  to the right, agree=0.744, adj=0.404, (0 split)
    ## 
    ## Node number 27: 31 observations
    ##   mean=67.02457, MSE=594.7673 
    ## 
    ## Node number 52: 447 observations
    ##   mean=33.6129, MSE=94.78169 
    ## 
    ## Node number 53: 337 observations
    ##   mean=42.91805, MSE=148.2579

![unnamed-chunk-10-1](https://user-images.githubusercontent.com/122301851/228051191-0268fcfe-3a62-4824-863b-2c89b60a220b.png)

#### Model 3: random forests.

    ##                 Length Class  Mode     
    ## call               4   -none- call     
    ## type               1   -none- character
    ## predicted       6256   -none- numeric  
    ## mse              500   -none- numeric  
    ## rsq              500   -none- numeric  
    ## oob.times       6256   -none- numeric  
    ## importance        28   -none- numeric  
    ## importanceSD      14   -none- numeric  
    ## localImportance    0   -none- NULL     
    ## proximity          0   -none- NULL     
    ## ntree              1   -none- numeric  
    ## mtry               1   -none- numeric  
    ## forest            11   -none- list     
    ## coefs              0   -none- NULL     
    ## y               6256   -none- numeric  
    ## test               0   -none- NULL     
    ## inbag              0   -none- NULL     
    ## terms              3   terms  call

![unnamed-chunk-11-1](https://user-images.githubusercontent.com/122301851/228051201-73bc54c7-343b-4b7b-9860-18a51b07de74.png)

#### Model 4: bagging.

    ##                 Length Class  Mode     
    ## call               4   -none- call     
    ## type               1   -none- character
    ## predicted       6256   -none- numeric  
    ## mse              500   -none- numeric  
    ## rsq              500   -none- numeric  
    ## oob.times       6256   -none- numeric  
    ## importance        14   -none- numeric  
    ## importanceSD       0   -none- NULL     
    ## localImportance    0   -none- NULL     
    ## proximity          0   -none- NULL     
    ## ntree              1   -none- numeric  
    ## mtry               1   -none- numeric  
    ## forest            11   -none- list     
    ## coefs              0   -none- NULL     
    ## y               6256   -none- numeric  
    ## test               0   -none- NULL     
    ## inbag              0   -none- NULL     
    ## terms              3   terms  call

![unnamed-chunk-12-1](https://user-images.githubusercontent.com/122301851/228051225-3d94b3ba-16d6-446e-9c68-ea25e6982ed8.png)

We compare RMSE between the four models using the testing data to find
the lowest. The four listed below are in the same order as identified
above. We find that the bagging model (the last one) has a lowest RMSE.

    ## [1] 8.767476

    ## [1] 9.878419

    ## [1] 6.409509

    ## [1] 6.345546

We therefore use the bagging model as our predictive model and calculate
out of sample prediction accuracy. We first see the bagging model for
mtry that resulted in the lowest RMSE and we find mtry = 4. We then fit
the model on the entire data and find the partial dependence plot and
variable importance plot.

    ## 
    ## Call:
    ##  randomForest(formula = revenue ~ size + empl_gr + stories + age +      renovated + class_a + class_b + green_rating + amenities +      total_dd_07 + Precipitation + Gas_Costs + Electricity_Costs +      City_Market_Rent, data = gb_train, replace = TRUE) 
    ##                Type of random forest: regression
    ##                      Number of trees: 500
    ## No. of variables tried at each split: 4
    ## 
    ##           Mean of squared residuals: 57.95613
    ##                     % Var explained: 77.28

    ## 
    ## Call:
    ##  randomForest(formula = revenue ~ size + empl_gr + stories + age +      renovated + class_a + class_b + green_rating + amenities +      total_dd_07 + Precipitation + Gas_Costs + Electricity_Costs +      City_Market_Rent, data = gb, replace = TRUE) 
    ##                Type of random forest: regression
    ##                      Number of trees: 500
    ## No. of variables tried at each split: 4
    ## 
    ##           Mean of squared residuals: 50.59859
    ##                     % Var explained: 79.22

![unnamed-chunk-14-1](https://user-images.githubusercontent.com/122301851/228051242-e3d11634-833b-4777-ab42-76e2a4cf9caf.png)
![unnamed-chunk-14-2](https://user-images.githubusercontent.com/122301851/228051254-7c6a7bd3-3ed9-44b0-b5db-1ff6178e53a5.png)

#### Conclusion:

Among the models we tested, we find that the best model is the random
forest model with the bagging method since it resulted in the lowest
RMSE. In this model, we find that the green rating variable has a
positive impact on predicted revenue with a magnitude of roughly 0.65.
In addition, we fidn that the percentage of variance explained by the
model is roughly 79.22%. However, we also find that the green rating
variable is the least important variable considered in the regression.

## Predictive model building: California housing.

We approach this problem with the same line of thought as the previous
problem. We first conduct model selection, then derive model parameters
and statistics, and lastly provide the necessary plots.

We use the same tree models as before (previous problem) to conduct
model selection.

We then compare the RMSE of each model using the testing data. The
results listed below are in the same order as the model identification
above. We find that bagging (the last one) gave the lowest RSME. We
therefore use it as our prediction model.

    ## [1] 76303.95

    ## [1] 49917.79

    ## [1] 46996.63

Below are the three required plots.

Original data.

![unnamed-chunk-18-1](https://user-images.githubusercontent.com/122301851/228051276-273ec16b-d7d4-46f5-8018-abf4afa4f971.png)

Predicted data. It looks very similar to the original data plot.
![unnamed-chunk-19-1](https://user-images.githubusercontent.com/122301851/228051287-6d4e55b9-961b-4d70-9052-bcc8abe8b588.png)

Residuals data. Since almost all the points in the plot are yellow,
residuals of the model are mostly very small. This means our prediction
model is a good fit to present the median value of California’s housing
situation. 
![unnamed-chunk-20-1](https://user-images.githubusercontent.com/122301851/228051310-18665e9b-3800-4537-a336-340cde10eb7a.png)
